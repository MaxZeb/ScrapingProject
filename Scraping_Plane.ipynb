{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "The scikit package for python will be one of the most important ones during the master programs. Therefore I came up with the idea to get a overview what topics are coverd on the documentation webpage and especially which external resources are provided. The apporoch would be to start at the highest level of the webpage and then go down the tree shaped website directory. I limit the analysis to 2 levels below the starting point, otherwise it would be computational challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import queue\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classes and functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(DRs):\n",
    "    try:\n",
    "        if len(DRs.get(\"class\")) > 1: \n",
    "            class_lap = str(\"\")\n",
    "            for i in range(len(DRs.get(\"class\"))):\n",
    "                class_lap = str(class_lap + DRs.get(\"class\")[i])\n",
    "            return class_lap\n",
    "        else: \n",
    "            return DRs.get(\"class\")\n",
    "    except:\n",
    "        \"Not Labeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_type(webdir):\n",
    "    if (webdir[0:4] == \"http\") or (webdir[-3:] == \"pdf\"):\n",
    "        return \"foreign\"\n",
    "    else: \n",
    "        return \"scikit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_scikit(webdir):\n",
    "    if website_type(webdir) == \"scikit\":\n",
    "        URL = \"http://scikit-learn.org/stable/\"\n",
    "        # webdir = \"documentation.html\"\n",
    "        next_url = str(URL + webdir)\n",
    "        soup = BeautifulSoup(requests.get(next_url).content, \"lxml\")\n",
    "        link_data = pd.DataFrame([])\n",
    "        if len(soup.select(\"div.body a\")) > 0:\n",
    "            for DRs in soup.select(\"div.body a\"):\n",
    "                link_data = link_data.append(pd.DataFrame({\"Website\": URL, \"Location\": webdir, \n",
    "                                                           \"Links\": DRs.get(\"href\"), \"Type\": get_class(DRs)}, \n",
    "                                                          index=[0])\n",
    "                                             , ignore_index=True)\n",
    "        else: \n",
    "            link_data = pd.DataFrame({\"Website\": URL, \"Location\": webdir, \"Links\": \"No Link here\", \"Type\": \"Not Labeled\"}, \n",
    "                                                      index=[0])\n",
    "    else: \n",
    "        link_data = pd.DataFrame({\"Website\": webdir, \"Location\": webdir, \"Links\": \"No Link here\", \"Type\": \"Not Labeled\"}, \n",
    "                                                      index=[0])\n",
    "    return link_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_worker(i):\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item == 'break':\n",
    "            break\n",
    "        results = get_links_scikit(item)\n",
    "        q.task_done()\n",
    "        if (q.unfinished_tasks in [2000,1500,1000,500,10]) or (q.unfinished_tasks < 10):\n",
    "            print(\"Task_done & amount of unfinished sub tasks: \" + str(q.unfinished_tasks))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_worker(i):\n",
    "    while True:\n",
    "        print(\"Amount of unfinished main tasks: \" + str(m.unfinished_tasks))\n",
    "        item = m.get()\n",
    "        if item == 'break':\n",
    "            break\n",
    "        results = get_links_scikit(item)\n",
    "        if any(results):\n",
    "            for x in results[\"Links\"]:\n",
    "                q.put(x)\n",
    "        m.task_done()\n",
    "        print(\"Task_done & amount of unfinished tasks: \" + str(q.unfinished_tasks))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simple worker with given list of links\n",
    "initial_tasks = list(get_links_scikit(\"documentation.html\")[\"Links\"])\n",
    "#del initial_tasks[3:5]\n",
    "q = queue.Queue()\n",
    "for y in initial_tasks: \n",
    "    q.put(y)\n",
    "with ThreadPoolExecutor(max_workers=500) as executor:\n",
    "    futures = executor.map(simple_worker,range(len(initial_tasks)))\n",
    "    q.join()\n",
    "    for i in range(500):\n",
    "        q.put('break')\n",
    "\n",
    "links = pd.DataFrame([])\n",
    "for value in futures:\n",
    "    links = links.append(value,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of unfinished main tasks: 13\n",
      "Amount of unfinished main tasks: 13\n",
      "Amount of unfinished main tasks: 13\n",
      "Amount of unfinished main tasks: 13\n",
      "Task_done & amount of unfinished tasks: 1\n",
      "Amount of unfinished main tasks: 12\n",
      "Task_done & amount of unfinished tasks: 2\n",
      "Amount of unfinished main tasks: 11\n",
      "Amount of unfinished main tasks: 11\n",
      "Amount of unfinished main tasks: 11\n",
      "Amount of unfinished main tasks: 11\n",
      "Amount of unfinished main tasks: 11Amount of unfinished main tasks: 11\n",
      "Amount of unfinished main tasks: 11\n",
      "\n",
      "Amount of unfinished main tasks: 11\n",
      "Task_done & amount of unfinished tasks: 33\n",
      "Task_done & amount of unfinished tasks: 61\n",
      "Task_done & amount of unfinished tasks: 62\n",
      "Task_done & amount of unfinished tasks: 109\n",
      "Task_done & amount of unfinished tasks: 185\n",
      "Task_done & amount of unfinished tasks: 273\n",
      "Task_done & amount of unfinished tasks: 323\n",
      "Task_done & amount of unfinished tasks: 364\n",
      "Task_done & amount of unfinished tasks: 928\n",
      "Task_done & amount of unfinished tasks: 1407\n",
      "Task_done & amount of unfinished tasks: 2080\n"
     ]
    }
   ],
   "source": [
    "# Hard worker\n",
    "m = queue.Queue()\n",
    "q = queue.Queue()\n",
    "\n",
    "initial_tasks = list(get_links_scikit(\"documentation.html\")[\"Links\"])\n",
    "for y in initial_tasks: \n",
    "    m.put(y)\n",
    "with ThreadPoolExecutor(max_workers=m.unfinished_tasks) as executor:\n",
    "    executor.map(hard_worker,range(m.unfinished_tasks))\n",
    "    m.join()\n",
    "    for i in range(m.unfinished_tasks):\n",
    "        m.put('break')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task_done & amount of unfinished sub tasks: 2000\n",
      "Task_done & amount of unfinished sub tasks: 1500\n",
      "Task_done & amount of unfinished sub tasks: 1000\n",
      "Task_done & amount of unfinished sub tasks: 500\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers= (q.unfinished_tasks+8)) as executor:\n",
    "    futures = executor.map(simple_worker,range((q.unfinished_tasks+8)))\n",
    "    q.join()\n",
    "    for i in range((q.unfinished_tasks+8)):\n",
    "        q.put('break')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.unfinished_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links = pd.DataFrame([])\n",
    "for value in futures:\n",
    "    links = links.append(value,ignore_index=True)\n",
    "# links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.to_csv(\"scikit_links.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore external links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_explore = pd.DataFrame(links[links.Type == \"referenceexternal\"])\n",
    "res = []\n",
    "full = []\n",
    "res2 = []\n",
    "for values in to_explore[\"Links\"]:\n",
    "    res2.append([s for s in values.split(\"/\")])\n",
    "    res.append([s for s in values.split(\".\") if \"/\" not in s])\n",
    "    full.append(values.split(\".\"))\n",
    "res\n",
    "full\n",
    "res2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
